{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7rSy8meD216"
   },
   "source": [
    "# Solving a 2nd order ODE with a feed-forward neural network using Autograd\n",
    "\n",
    "Ordinary differential equations (ODEs) are crucial for modeling physical, chemical, financial, etc phenomena. Here, a neural network is used to numerically calculate to approximate a solution 2nd order ODE. The finite-difference method, of course, is a more reliable method for calculating solutions; however, the use of neural networks could prove useful in certain situations. \n",
    "\n",
    "In this notebook, a multi-layer perceptron neural network is used. \n",
    "\n",
    "Consider the following 2nd order ODE:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d^2y(t)}{dt^2} = -k^2 y(t) \n",
    "\\end{align}\n",
    "\n",
    "The analytical solution to this ODE is $y(t) = \\sin(kx)$ where $$y(0) = 0$$ $$y'(0) = k$$\n",
    "\n",
    "\n",
    "References:<br>\n",
    "[1] J. Kitchin, example of solving 1D ODE with NN http://kitchingroup.cheme.cmu.edu/blog/2017/11/28/Solving-ODEs-with-a-neural-network-and-autograd/ <br>\n",
    "[2] Sine activation functions https://openreview.net/pdf?id=Sks3zF9eg <br>\n",
    "[3] Long short-term memory neural network (not implemented here) https://link.springer.com/chapter/10.1007/978-3-319-47054-2_10/fulltext.html <br>\n",
    "[4] Solving DE using neural networks https://becominghuman.ai/neural-networks-for-solving-differential-equations-fa230ac5e04c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 2580,
     "status": "ok",
     "timestamp": 1521780672232,
     "user": {
      "displayName": "Brent DeVetter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110290226878953433531"
     },
     "user_tz": 420
    },
    "id": "bf2S-_FKDttm",
    "outputId": "c2a68da9-129d-4401-b32f-63d9c38a5622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autograd\n",
      "  Downloading https://files.pythonhosted.org/packages/08/7a/1ccee2a929d806ba3dbe632a196ad6a3f1423d6e261ae887e5fef2011420/autograd-1.2.tar.gz\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/brentdevetter/anaconda/lib/python3.5/site-packages (from autograd)\n",
      "Collecting future>=0.15.2 (from autograd)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/2b/8d082ddfed935f3608cc61140df6dcbf0edea1bc3ab52fb6c29ae3e81e85/future-0.16.0.tar.gz (824kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 582kB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: autograd, future\n",
      "  Running setup.py bdist_wheel for autograd ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/brentdevetter/Library/Caches/pip/wheels/72/6f/c2/40f130cca2c91f31d354bf72de282922479c09ce0b7853c4c5\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/brentdevetter/Library/Caches/pip/wheels/bf/c9/a3/c538d90ef17cf7823fa51fc701a7a7a910a80f6a405bf15b1a\n",
      "Successfully built autograd future\n",
      "Installing collected packages: future, autograd\n",
      "Successfully installed autograd-1.2 future-0.16.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libararies / functions\n",
    "!pip install autograd\n",
    "\n",
    "from autograd import grad, elementwise_grad\n",
    "from autograd.misc.optimizers import adam\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "import math\n",
    "\n",
    "# Possible activation functions\n",
    "def swish(x):\n",
    "    return x / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "  \n",
    "def periodic(x):\n",
    "    return np.sin(x)\n",
    "  \n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXbE4I-VK0uM"
   },
   "source": [
    "As described in reference [4], the ODE is solved by minimizing an objective function.  <br>\n",
    "\n",
    "\\begin{align}\n",
    "z_{eq} = \\frac{d^2y(t)}{dt^2} + k^2 y(t) = 0 \\\\ \n",
    "ic = y(0) - 0 = 0 \\\\\n",
    "ic_2  = \\frac{dy(0)}{dt} - k = 0 \\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\Psi = z_{eq}^2 + ic^2 + ic_2^2 \\\\ \n",
    "\\end{align}\n",
    "\n",
    "Where $\\Psi$ is minimized. First we attempt calculating the solution to this ODE using a 3-layer neural network with 100 hidden nodes. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 166,
     "output_extras": [
      {
       "item_id": 8
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 70974,
     "status": "ok",
     "timestamp": 1521783036892,
     "user": {
      "displayName": "Brent DeVetter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110290226878953433531"
     },
     "user_tz": 420
    },
    "id": "oEkZzuXOKGnC",
    "outputId": "f4c74f6e-cef3-4f8b-c121-31b4ffac0afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   0 Objective: 0.9326984741285588\n",
      "Iteration: 1000 Objective: 0.04799555951089569\n",
      "Iteration: 2000 Objective: 0.02916355931368044\n",
      "Iteration: 3000 Objective: 0.02655550884375522\n",
      "Iteration:   0 Objective: 0.9326984741285588\n",
      "Iteration: 1000 Objective: 0.5572130997130831\n",
      "Iteration: 2000 Objective: 0.8146232550700254\n",
      "Iteration: 3000 Objective: 0.9092899701086645\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, assume k is 1\n",
    "k = 1\n",
    "  \n",
    "t = np.linspace(0, math.pi*3).reshape((-1, 1))\n",
    "\n",
    "# ODE function using a swish activation function\n",
    "def ode_func(params, inputs):\n",
    "  for W, b in params:\n",
    "    outputs = np.dot(inputs, W) + b          \n",
    "    inputs = swish(outputs)                   \n",
    "  return outputs\n",
    "\n",
    "# ODE function using a periodic (sine) activation function \n",
    "def ode_func_periodic(params, inputs):\n",
    "  for W, b in params:\n",
    "    outputs = np.dot(inputs, W) + b          \n",
    "    inputs = periodic(outputs)              \n",
    "  return outputs\n",
    "\n",
    "\n",
    "# Derivatives\n",
    "deriv_ode_func = elementwise_grad(ode_func, 1)\n",
    "deriv_2_ode_func = elementwise_grad(deriv_ode_func, 1)\n",
    "\n",
    "deriv_ode_func_periodic = elementwise_grad(ode_func_periodic, 1)\n",
    "deriv_2_ode_func_periodic = elementwise_grad(deriv_ode_func_periodic, 1)\n",
    "\n",
    "def setup_init_nn(scale, layer_sizes):\n",
    "  rs = npr.RandomState(0)\n",
    "  \n",
    "  return [ (rs.randn(insize, outsize) * scale, # weight matrix\n",
    "            rs.randn(outsize) * scale)         # bias vector\n",
    "           for insize, outsize in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "\n",
    "# This function is minimized\n",
    "def objective(params, step):\n",
    "  zeq = deriv_2_ode_func(params, t) + k*k * ode_func(params, t)\n",
    "  ic = deriv_ode_func(params, 0.0) - k\n",
    "  ic2 = deriv_2_ode_func(params, 0.0)\n",
    "  return np.mean(zeq**2) + ic**2 + ic2**2\n",
    "\n",
    "# This function is minimized (periodic)\n",
    "def objective_periodic(params, step):\n",
    "  zeq = deriv_2_ode_func_periodic(params, t) + k*k * ode_func_periodic(params, t)\n",
    "  ic = deriv_ode_func_periodic(params, 0.0) - k\n",
    "  ic2 = deriv_2_ode_func_periodic(params, 0.0)\n",
    "  return np.mean(zeq**2) + ic**2 + ic2**2\n",
    "\n",
    "def callback(params, step, g):\n",
    "  if step % 1000 == 0:\n",
    "    print(\"Iteration: {0:3d} Objective: {1}\".format(step, objective(params, step)))\n",
    "\n",
    "params_swish = setup_init_nn(0.1, layer_sizes = [1, 100, 1])  \n",
    "params_swish = adam(grad(objective), params_swish, step_size = 0.001, num_iters = 4000, callback = callback)\n",
    "\n",
    "params_periodic = setup_init_nn(0.1, layer_sizes = [1, 100, 1])  \n",
    "params_periodic = adam(grad(objective_periodic), params_periodic, step_size = 0.001, num_iters = 4000, callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 384,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1521783427620,
     "user": {
      "displayName": "Brent DeVetter",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110290226878953433531"
     },
     "user_tz": 420
    },
    "id": "CpbG5uhALuR-",
    "outputId": "935a17e7-8ae2-4e40-d49a-05d5c30aa4bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfit = np.linspace(0, math.pi*6).reshape(-1, 1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tfit, ode_func(params_swish, tfit), 'r--', label='NN Solution (swish)')\n",
    "plt.plot(tfit, ode_func_periodic(params_periodic, tfit), label='NN Solution (sine)')\n",
    "plt.plot(tfit, np.sin(k*tfit), 'k', label='Analytic Solution ')\n",
    "plt.plot()\n",
    "plt.legend()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('$y(t)$')   \n",
    "plt.xlim([0, math.pi*6])\n",
    "plt.ylim([-4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29ZCxRfuVsp0"
   },
   "source": [
    "The above figure shows that using a sine activation function results in a significantly better fit to data beyond the interval $[0, 3\\pi]$, which the neural network was trained. Of course, this is a tad artificial because the analytic solution is sinusoidal. Additional experimention is necessary to determine how well an semi-arbitrary periodic function behaves with respect to different activation functions. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "ode_nn_2ndorder.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
